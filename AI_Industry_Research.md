- [1. 半导体技术不断发展以满足生成式人工智能的需求](#1-半导体技术不断发展以满足生成式人工智能的需求)
  - [1.1 HBM4 将如何发展？](#11-hbm4-将如何发展)
  - [1.2 封装趋势转向玻璃基板和小芯片](#12-封装趋势转向玻璃基板和小芯片)
- [2. AI市场格局](#2-ai市场格局)
  - [2.1 生成式AI头部企业市场份额](#21-生成式ai头部企业市场份额)
- [3. 数据中心AI芯片路线图](#3-数据中心ai芯片路线图)
- [4. AI带来的机会](#4-ai带来的机会)
  - [4.1 中信建投2023分析](#41-中信建投2023分析)
    - [4.1.1 大算力时代的先进封装投资机遇](#411-大算力时代的先进封装投资机遇)
    - [4.1.2 算力产业链](#412-算力产业链)

<div STYLE="page-break-after: always;"></div>

# 1. 半导体技术不断发展以满足生成式人工智能的需求

## 1.1 HBM4 将如何发展？   
生成式人工智能和高性能计算 (HPC) 正在推动数据中心动态随机存取存储器 (DRAM) 需求的增长。

![image1](/picture/img_gen-ai-hbm-product-development_yint_july-2024-1-1024x662.jpg)

Yole Group 预测，2023 年至 2029 年间，高带宽存储器 (HBM) 的出货量将增长约 48%，HBM 在 DRAM 市场的份额将从 2023 年的 2% 左右上升至 6% 以上。

Yole Group 的拆解显示，NVIDIA 在其 Hopper Tensor Core H100 GPU 中引入了一种创新设计，该设计使用 HBM3，提供比其前身 A100 多两倍的 DRAM 带宽。该 GPU 与 Grace CPU 配对，使用 NVIDIA 的超高速芯片间互连，提供 900GB/s 的带宽，为 HPC、AI 和游戏市场运行 TB 级数据的应用程序提供高达 10 倍的性能。

HBM 目前掌握在三家主要厂商手中——SK 海力士、三星和美光。SK 海力士很可能在 2026 年率先推出 HBM4，但是否会使用混合键合仍有待观察。下一代混合键合可使用更小的连接来实现更密集的堆栈。

## 1.2 封装趋势转向玻璃基板和小芯片
目前AI加速器的平均基板尺寸约为70*70mm²，下一代产品有望向更大的尺寸发展，但当尺寸达到100*100mm²时，这一趋势就开始受到限制，超过这个限制，良率就会急剧下降。

并非所有当前的 AI 加速器都使用最大层数，但下一代产品预计将迅速采用更高的层数，以应对信号布线和电力传输挑战以及增大的尺寸。
![image2](/picture/img_high_end_performance_packaging_all-platforms_yg_july2024-1-1024x662.jpg)


提高可扩展性的一种方法是采用玻璃作为新的核心材料，将先进基板提升到一个新的水平。玻璃芯基板可以提供更小的 L/S、更少的层数和卓越的热导率，使其成为解决热管理问题的有希望的候选者。

![image3](/picture/img-status-of-the-advanced-ic-substrates-industry_option-for-datacenters_yint_july2024-1-1024x662.jpg)

Yole Group 预计，随着制造商寻求优化成本和性能，芯片组方法将在未来占据主导地位。芯片组支持分解，因此片上系统 (SoC) 单片芯片被划分为具有不同功能的较小芯片，然后在同一封装中互连。芯片组还允许复制，因此两个或多个 SoC 单片芯片可以在同一封装中互连以形成更大的 SoC。

<https://www.yolegroup.com/strategy-insights/semiconductor-technologies-evolving-to-meet-generative-ai-demand/>

# 2. AI市场格局

## 2.1 生成式AI头部企业市场份额

![image](picture/AI-market%202023.png)

<https://seekingalpha.com/article/4714331-intel-stock-debt-burden-far-from-competitive-sell>

# 3. 数据中心AI芯片路线图

这份 话题标签#datacenter 话题标签#AI 话题标签#chip 路线图显示，英伟达 将在 2027 年及以后💡占据主导地位。该数据中心 AI 芯片路线图显示，NVIDIA 在 AI 话题标签#GPU 业务中占据主导地位：直到 2027 年配备 576GB 话题标签#HBM4 内存的 Rubin Ultra AI GPU！

在最近分享的数据中心 AI 芯片路线图中 X 上发布，TweakTown 很好地了解了公司已经在市场上拥有的产品，以及到 2027 年的 AI 芯片管道中有哪些。看看吧：

该名单包括 话题标签#NVIDIA 、AMD 、英特尔 、谷歌 、亚马逊 、微软 、Meta 、字节跳动 和 华为 的芯片制造商。您可以查看 NVIDIA AI GPU 列表，包括 Ampere A100 到 Hopper H100、GH200、H200 AI GPU，以及 Blackwell B200A、B200 Ultra、GB200 Ultra 和 GB200A。但在那之后 - 我们都知道即将到来 - 是 Rubin 和 Rubin Ultra，两者都是下一代 HBM4 话题标签#memory 。

非常感谢 Anthony Garreffa 和 TweakTown 通过下面的💡🙏👇链接提供完整文章，其中包含更多背景和见解
<https://www.tweaktown.com/news/100151/this-data-center-ai-chip-roadmap-shows-nvidia-will-dominate-far-into-2027-and-beyond/index.html>

![image](/picture/AI%20datacenter.jpg)

# 4. AI带来的机会

## 4.1 中信建投2023分析

人工智能开启算力时代，先进制造筑牢硬件底座。AIGC引发内容生成范式革命，云端算法向大模型多模态演进，硬件基础设施成为发展基石，算力芯片等环节核心受益，英伟达、AMD对华供应高端GPU芯片受限背景下，国产算力芯片迎来国产替代窗口期。此外，后摩尔时代算力需求爆发，一方面，急需高性价比解决方案，先进封装工艺迭代成为新的发展趋势，国内封测龙头正积极布局；另一方面，先进制程在台积电等龙头竞争下迈入3nm时代，国内晶圆代工厂也在攻关FinFET架构的先进制程，有望为大算力芯片提供先进制造工艺。

### 4.1.1 大算力时代的先进封装投资机遇

大算力应用如高性能服务器（HPC）和自动驾驶（ADAS）取代手机/PC成为新一轮半导体周期驱动力，后摩尔定律时代高端封装工艺迭代成为新的发展趋势。以Chiplet为代表的2.5D/3D封装形式成为大芯片标配，TSV/RDL/Fan-out等高端封装技术带来封装环节价值占比提升。全球晶圆代工龙头台积电打造全球2.5D/3D先进封装工艺标杆，未来几年封装市场增长主要受益于先进封装的扩大。先进封装市场的快速增长，有望成为国内晶圆代工厂商与封测厂商的新一轮成长驱动力。

1、应用：大算力应用如高性能服务器（HPC）和自动驾驶（ADAS）取代手机/PC成为新一轮半导体周期驱动力，后摩尔定律时代高端封装工艺迭代成为新的发展趋势。以台积电下游应用来看，HPC的收入增速从2020年Q3超过手机后保持持续领先，对应的营收占比在在2022年Q1首次超过手机成为台积电下游第一大应用，相比之下封测厂商在高价值量的运算类电子占比仅为16%。我们认为随着大算力需求提升，先进封装替代先进制程成为降低单位算力成本的最佳方案，进而拉高运算电子在封测厂商的价值量。

2、工艺：以Chiplet为代表的2.5D/3D封装形式成为大芯片标配，TSV/RDL/Fan-out等高端封装技术带来封装环节价值占比提升。半导体价值量的增长下游从手机/PC向高算力的HPC和ADAS转移，封装工艺开始向Chiplet为代表的2.5D/3D封装转移，从封装工艺流程来看，晶圆代工厂基于制造环节的的优势扩展至TSV工艺，封测厂参与较多的是RDL和Fan-out等封装工艺，随着高算力芯片整体封测市场扩容，封测厂商逐步扩大2.5D和3D封测布局。

3、市场：全球晶圆代工龙头台积电打造全球2.5D/3D先进封装工艺标杆，未来几年封装市场增长主要受益于先进封装的扩大。目前先进封装营收规模最大是晶圆代工龙头台积电，预计2022年先进封装贡献了53亿美元，全球封测龙头日月光和安靠都推出了3D封测工艺平台，积极抢占先进封装的份额。预计2027年先进封装市场规模增至651亿美元，2021-2027年CAGR达到9.6%，先进封装成为大算力时代封装厂商新的增长动能。

### 4.1.2 算力产业链

算力产业链价值放量顺序如下：先进制程制造->以Chiplet为代表的2.5D/3D封装、HBM->AI芯片->板卡组装->交换机->光模块->液冷->AI服务器->IDC出租运维。

**先进封装、HBM**：为了解决先进制程成本快速提升和“内存墙”等问题，Chiplet设计+异构先进封装成为性能与成本平衡的最佳方案，台积电开发的CoWoS封装技术可以实现计算核心与HBM通过2.5D封装互连，因此英伟达A100、H100等AI芯片纷纷采用台积电CoWos封装，并分别配备40GB HBM2E、80GB的HBM3内存。全球晶圆代工龙头台积电打造全球2.5D/3D先进封装工艺标杆，未来几年封装市场增长主要受益于先进封装的扩产。

**AI芯片/板卡封装**：以英伟达为代表，今年二季度开始释放业绩。模型训练需要规模化的算力芯片部署于智能服务器，CPU不可或缺，但性能提升遭遇瓶颈，CPU+xPU异构方案成为大算力场景标配。其中GPU并行计算优势明显，CPU+GPU成为目前最流行的异构计算系统，而NPU在特定场景下的性能、效率优势明显，推理端应用潜力巨大，随着大模型多模态发展，硬件需求有望从GPU扩展至周边编解码硬件。

AI加速芯片市场上，英伟达凭借其硬件产品性能的先进性和生态构建的完善性处于市场领导地位，在训练、推理端均占据领先地位。根据Liftr Insights数据，2022年数据中心AI加速市场中，英伟达份额达82%。因此AI芯片需求爆发，英伟达最为受益，其 Q2收入指引110亿美金，预计其数据中心芯片业务收入接近翻倍。国内厂商虽然在硬件产品性能和产业链生态架构方面与前者有所差距，但正在逐步完善产品布局和生态构建，不断缩小与行业龙头厂商的差距，并且英伟达、AMD对华供应高端GPU芯片受限，国产算力芯片迎来国产替代窗口期。

**交换机**：与传统数据中心的网络架构相比，AI数据网络架构会带来更多的交换机端口的需求。交换机具备技术壁垒，中国市场格局稳定。

**光模块**：AI算力带动数据中心内部数据流量较大，光模块速率及数量均有显著提升。训练侧光模块需求与GPU出货量强相关，推理侧光模块需求与数据流量强相关，伴随应用加速渗透，未来推理所需的算力和流量实际上可能远大于训练。目前，训练侧英伟达的A100 GPU主要对应200G光模块和400G光模块，H100 GPU可以对应400G或800G光模块。

根据我们的测算，训练端A100和200G光模块的比例是1：7，H100和800G光模块的比例是1：3.5。800G光模块2022年底开始小批量出货，2023年需求主要来自于英伟达和谷歌。在2023年这个时间点，市场下一代高速率光模块均指向800G光模块，叠加AIGC带来的算力和模型竞赛，我们预计北美各大云厂商和相关科技巨头均有望在2024年大量采购800G光模块，同时2023年也可能提前采购。

**光模块上游——光芯片**：以AWG、PLC等为代表的无源光芯片，国内厂商市占率全球领先。以EEL、VCSEL、DFB等激光器芯片、探测器芯片和调制器芯片为代表的有源光芯片是现代光学技术的重要基石，是有源光器件的重要组成部分。

**液冷**：AI大模型训练和推理所用的GPU服务器功率密度将大幅提升，以英伟达DGX A100服务器为例，其单机最大功率约可达到6.5kW，大幅超过单台普通CPU服务器500w左右的功率水平。

根据《冷板式液冷服务器可靠性白皮书》数据显示，自然风冷的数据中心单柜密度一般只支持8kW-10kW，通常液冷数据中心单机柜可支持30kW以上的散热能力，并能较好演进到100kW以上，相较而言液冷的散热能力和经济性均有明显优势。同时“东数西算” 明确PUE（数据中心总能耗/IT设备能耗）要求，枢纽节点PUE要求更高，同时考虑到整体规划布局，未来新增机柜更多将在枢纽节点内，风冷方案在某些地区可能无法严格满足要求，液冷方案渗透率有望加速提升。目前在AI算力需求的推动下，如浪潮信息、中兴通讯等服务器厂商已经开始大力布局液冷服务器产品。在液冷方案加速渗透过程中，数据中心温控厂商、液冷板制造厂商等有望受益。

**AI服务器**：预计今年Q2-Q3开始逐步释放业绩。具体来看，训练型AI服务器成本中，约7成以上由GPU构成，其余CPU、存储、内存等占比相对较小，均价常达到百万元以上。对于推理型服务器，其GPU成本约为2-3成，整体成本构成与高性能型相近，价格常在20-30万。根据IDC数据，2022年全球AI服务器市场规模202亿美元，同比增长29.8%，占服务器市场规模的比例为16.4%，同比提升1.2pct。

我们认为全球AI服务器市场规模未来3年内将保持高速增长，市场规模分别为395/890/1601亿美元，对应增速96%/125%/80%。根据IDC数据，2022年中国AI服务器市场规模67亿美元，同比增长24%。我们预计，2023-2025年，结合对于全球AI服务器市场规模的预判，以及对于我国份额占比持续提升的假设，我国AI服务器市场规模有望达到134/307/561亿美元，同比增长101%/128%/83%。竞争格局方面，考虑到AI服务器研发和投入上需要更充足的资金及技术支持，国内市场的竞争格局预计将继续向头部集中，保持一超多强的竞争格局。

**IDC**：在数字中国和人工智能推动云计算市场回暖的背景下，IDC作为云基础设施产业链的关键环节，也有望进入需求释放阶段。在过去两年半，受多重因素影响下，云计算需求景气度下行，但IDC建设与供给未出现明显放缓，2021年和2022年分别新增机柜数量120万架和150万架，因此短期内出现供需失衡情况（核心区域供需状况相对良好），部分地区上电率情况一般。所以IDC公司2022年业绩普遍承压。

当前，我们认为国内IDC行业有望边际向好。随着宏观经济向好，平台经济发展恢复，AI等拉动，IDC需求有望逐步释放，叠加2023新增供给量有望较2022年减少（例如三大运营商2022年新增IDC机柜15.6万架，2023年计划新增11.4万架）。展望未来，电信运营商在云计算业务方面仍将实现快速增长，百度、字节跳动等互联网公司在AIGC领域有望实现突破性进展，都将对包括IDC在内的云基础设施产生较大新增需求，相关IDC厂商有望获益。

<https://finance.sina.cn/stock/ggyj/2023-10-21/detail-imzrvyzn4754692.d.html?vt=4>

