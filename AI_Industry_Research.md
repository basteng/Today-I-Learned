# 3. 半导体技术不断发展以满足生成式人工智能的需求

1.HBM4 将如何发展？   
生成式人工智能和高性能计算 (HPC) 正在推动数据中心动态随机存取存储器 (DRAM) 需求的增长。

![image1](/picture/img_gen-ai-hbm-product-development_yint_july-2024-1-1024x662.jpg)

Yole Group 预测，2023 年至 2029 年间，高带宽存储器 (HBM) 的出货量将增长约 48%，HBM 在 DRAM 市场的份额将从 2023 年的 2% 左右上升至 6% 以上。

Yole Group 的拆解显示，NVIDIA 在其 Hopper Tensor Core H100 GPU 中引入了一种创新设计，该设计使用 HBM3，提供比其前身 A100 多两倍的 DRAM 带宽。该 GPU 与 Grace CPU 配对，使用 NVIDIA 的超高速芯片间互连，提供 900GB/s 的带宽，为 HPC、AI 和游戏市场运行 TB 级数据的应用程序提供高达 10 倍的性能。

HBM 目前掌握在三家主要厂商手中——SK 海力士、三星和美光。SK 海力士很可能在 2026 年率先推出 HBM4，但是否会使用混合键合仍有待观察。下一代混合键合可使用更小的连接来实现更密集的堆栈。

2.封装趋势转向玻璃基板和小芯片
目前AI加速器的平均基板尺寸约为70*70mm²，下一代产品有望向更大的尺寸发展，但当尺寸达到100*100mm²时，这一趋势就开始受到限制，超过这个限制，良率就会急剧下降。

并非所有当前的 AI 加速器都使用最大层数，但下一代产品预计将迅速采用更高的层数，以应对信号布线和电力传输挑战以及增大的尺寸。
![image2](/picture/img_high_end_performance_packaging_all-platforms_yg_july2024-1-1024x662.jpg)


提高可扩展性的一种方法是采用玻璃作为新的核心材料，将先进基板提升到一个新的水平。玻璃芯基板可以提供更小的 L/S、更少的层数和卓越的热导率，使其成为解决热管理问题的有希望的候选者。

![image3](/picture/img-status-of-the-advanced-ic-substrates-industry_option-for-datacenters_yint_july2024-1-1024x662.jpg)

Yole Group 预计，随着制造商寻求优化成本和性能，芯片组方法将在未来占据主导地位。芯片组支持分解，因此片上系统 (SoC) 单片芯片被划分为具有不同功能的较小芯片，然后在同一封装中互连。芯片组还允许复制，因此两个或多个 SoC 单片芯片可以在同一封装中互连以形成更大的 SoC。

<https://www.yolegroup.com/strategy-insights/semiconductor-technologies-evolving-to-meet-generative-ai-demand/>