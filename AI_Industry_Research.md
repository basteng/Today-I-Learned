- [1. 半导体技术不断发展以满足生成式人工智能的需求](#1-半导体技术不断发展以满足生成式人工智能的需求)
  - [1.1 HBM4 将如何发展？](#11-hbm4-将如何发展)
  - [1.2 封装趋势转向玻璃基板和小芯片](#12-封装趋势转向玻璃基板和小芯片)
- [2. AI市场格局](#2-ai市场格局)
  - [2.1 生成式AI头部企业市场份额](#21-生成式ai头部企业市场份额)
- [3. 数据中心AI芯片路线图](#3-数据中心ai芯片路线图)
- [4. AI带来的机会](#4-ai带来的机会)
  - [4.1 中信建投2023分析](#41-中信建投2023分析)
    - [4.1.1 大算力时代的先进封装投资机遇](#411-大算力时代的先进封装投资机遇)
    - [4.1.2 算力产业链](#412-算力产业链)
  - [4.2 广发证券](#42-广发证券)
    - [4.2.1 先进工艺、先进设备](#421-先进工艺先进设备)
    - [4.2.2 Retimer和CXL](#422-retimer和cxl)
    - [4.2.3 AI服务器PCB](#423-ai服务器pcb)
    - [4.2.4 以太网交换机](#424-以太网交换机)
  - [4.2.5 总结：算、连、存是AI算力硬件的核心](#425-总结算连存是ai算力硬件的核心)

<div STYLE="page-break-after: always;"></div>

# 1. 半导体技术不断发展以满足生成式人工智能的需求

## 1.1 HBM4 将如何发展？   
生成式人工智能和高性能计算 (HPC) 正在推动数据中心动态随机存取存储器 (DRAM) 需求的增长。

![image1](/picture/img_gen-ai-hbm-product-development_yint_july-2024-1-1024x662.jpg)

Yole Group 预测，2023 年至 2029 年间，高带宽存储器 (HBM) 的出货量将增长约 48%，HBM 在 DRAM 市场的份额将从 2023 年的 2% 左右上升至 6% 以上。

Yole Group 的拆解显示，NVIDIA 在其 Hopper Tensor Core H100 GPU 中引入了一种创新设计，该设计使用 HBM3，提供比其前身 A100 多两倍的 DRAM 带宽。该 GPU 与 Grace CPU 配对，使用 NVIDIA 的超高速芯片间互连，提供 900GB/s 的带宽，为 HPC、AI 和游戏市场运行 TB 级数据的应用程序提供高达 10 倍的性能。

HBM 目前掌握在三家主要厂商手中——SK 海力士、三星和美光。SK 海力士很可能在 2026 年率先推出 HBM4，但是否会使用混合键合仍有待观察。下一代混合键合可使用更小的连接来实现更密集的堆栈。

## 1.2 封装趋势转向玻璃基板和小芯片
目前AI加速器的平均基板尺寸约为70*70mm²，下一代产品有望向更大的尺寸发展，但当尺寸达到100*100mm²时，这一趋势就开始受到限制，超过这个限制，良率就会急剧下降。

并非所有当前的 AI 加速器都使用最大层数，但下一代产品预计将迅速采用更高的层数，以应对信号布线和电力传输挑战以及增大的尺寸。
![image2](/picture/img_high_end_performance_packaging_all-platforms_yg_july2024-1-1024x662.jpg)


提高可扩展性的一种方法是采用玻璃作为新的核心材料，将先进基板提升到一个新的水平。玻璃芯基板可以提供更小的 L/S、更少的层数和卓越的热导率，使其成为解决热管理问题的有希望的候选者。

![image3](/picture/img-status-of-the-advanced-ic-substrates-industry_option-for-datacenters_yint_july2024-1-1024x662.jpg)

Yole Group 预计，随着制造商寻求优化成本和性能，芯片组方法将在未来占据主导地位。芯片组支持分解，因此片上系统 (SoC) 单片芯片被划分为具有不同功能的较小芯片，然后在同一封装中互连。芯片组还允许复制，因此两个或多个 SoC 单片芯片可以在同一封装中互连以形成更大的 SoC。

<https://www.yolegroup.com/strategy-insights/semiconductor-technologies-evolving-to-meet-generative-ai-demand/>

# 2. AI市场格局

## 2.1 生成式AI头部企业市场份额

![image](picture/AI-market%202023.png)

<https://seekingalpha.com/article/4714331-intel-stock-debt-burden-far-from-competitive-sell>

# 3. 数据中心AI芯片路线图

这份 话题标签#datacenter 话题标签#AI 话题标签#chip 路线图显示，英伟达 将在 2027 年及以后💡占据主导地位。该数据中心 AI 芯片路线图显示，NVIDIA 在 AI 话题标签#GPU 业务中占据主导地位：直到 2027 年配备 576GB 话题标签#HBM4 内存的 Rubin Ultra AI GPU！

在最近分享的数据中心 AI 芯片路线图中 X 上发布，TweakTown 很好地了解了公司已经在市场上拥有的产品，以及到 2027 年的 AI 芯片管道中有哪些。看看吧：

该名单包括 话题标签#NVIDIA 、AMD 、英特尔 、谷歌 、亚马逊 、微软 、Meta 、字节跳动 和 华为 的芯片制造商。您可以查看 NVIDIA AI GPU 列表，包括 Ampere A100 到 Hopper H100、GH200、H200 AI GPU，以及 Blackwell B200A、B200 Ultra、GB200 Ultra 和 GB200A。但在那之后 - 我们都知道即将到来 - 是 Rubin 和 Rubin Ultra，两者都是下一代 HBM4 话题标签#memory 。

非常感谢 Anthony Garreffa 和 TweakTown 通过下面的💡🙏👇链接提供完整文章，其中包含更多背景和见解
<https://www.tweaktown.com/news/100151/this-data-center-ai-chip-roadmap-shows-nvidia-will-dominate-far-into-2027-and-beyond/index.html>

![image](/picture/AI%20datacenter.jpg)

# 4. AI带来的机会

## 4.1 中信建投2023分析

人工智能开启算力时代，先进制造筑牢硬件底座。AIGC引发内容生成范式革命，云端算法向大模型多模态演进，硬件基础设施成为发展基石，算力芯片等环节核心受益，英伟达、AMD对华供应高端GPU芯片受限背景下，国产算力芯片迎来国产替代窗口期。此外，后摩尔时代算力需求爆发，一方面，急需高性价比解决方案，先进封装工艺迭代成为新的发展趋势，国内封测龙头正积极布局；另一方面，先进制程在台积电等龙头竞争下迈入3nm时代，国内晶圆代工厂也在攻关FinFET架构的先进制程，有望为大算力芯片提供先进制造工艺。

### 4.1.1 大算力时代的先进封装投资机遇

大算力应用如高性能服务器（HPC）和自动驾驶（ADAS）取代手机/PC成为新一轮半导体周期驱动力，后摩尔定律时代高端封装工艺迭代成为新的发展趋势。以Chiplet为代表的2.5D/3D封装形式成为大芯片标配，TSV/RDL/Fan-out等高端封装技术带来封装环节价值占比提升。全球晶圆代工龙头台积电打造全球2.5D/3D先进封装工艺标杆，未来几年封装市场增长主要受益于先进封装的扩大。先进封装市场的快速增长，有望成为国内晶圆代工厂商与封测厂商的新一轮成长驱动力。

1、应用：大算力应用如高性能服务器（HPC）和自动驾驶（ADAS）取代手机/PC成为新一轮半导体周期驱动力，后摩尔定律时代高端封装工艺迭代成为新的发展趋势。以台积电下游应用来看，HPC的收入增速从2020年Q3超过手机后保持持续领先，对应的营收占比在在2022年Q1首次超过手机成为台积电下游第一大应用，相比之下封测厂商在高价值量的运算类电子占比仅为16%。我们认为随着大算力需求提升，先进封装替代先进制程成为降低单位算力成本的最佳方案，进而拉高运算电子在封测厂商的价值量。

2、工艺：以Chiplet为代表的2.5D/3D封装形式成为大芯片标配，TSV/RDL/Fan-out等高端封装技术带来封装环节价值占比提升。半导体价值量的增长下游从手机/PC向高算力的HPC和ADAS转移，封装工艺开始向Chiplet为代表的2.5D/3D封装转移，从封装工艺流程来看，晶圆代工厂基于制造环节的的优势扩展至TSV工艺，封测厂参与较多的是RDL和Fan-out等封装工艺，随着高算力芯片整体封测市场扩容，封测厂商逐步扩大2.5D和3D封测布局。

3、市场：全球晶圆代工龙头台积电打造全球2.5D/3D先进封装工艺标杆，未来几年封装市场增长主要受益于先进封装的扩大。目前先进封装营收规模最大是晶圆代工龙头台积电，预计2022年先进封装贡献了53亿美元，全球封测龙头日月光和安靠都推出了3D封测工艺平台，积极抢占先进封装的份额。预计2027年先进封装市场规模增至651亿美元，2021-2027年CAGR达到9.6%，先进封装成为大算力时代封装厂商新的增长动能。

### 4.1.2 算力产业链

算力产业链价值放量顺序如下：先进制程制造->以Chiplet为代表的2.5D/3D封装、HBM->AI芯片->板卡组装->交换机->光模块->液冷->AI服务器->IDC出租运维。

**先进封装、HBM**：为了解决先进制程成本快速提升和“内存墙”等问题，Chiplet设计+异构先进封装成为性能与成本平衡的最佳方案，台积电开发的CoWoS封装技术可以实现计算核心与HBM通过2.5D封装互连，因此英伟达A100、H100等AI芯片纷纷采用台积电CoWos封装，并分别配备40GB HBM2E、80GB的HBM3内存。全球晶圆代工龙头台积电打造全球2.5D/3D先进封装工艺标杆，未来几年封装市场增长主要受益于先进封装的扩产。

**AI芯片/板卡封装**：以英伟达为代表，今年二季度开始释放业绩。模型训练需要规模化的算力芯片部署于智能服务器，CPU不可或缺，但性能提升遭遇瓶颈，CPU+xPU异构方案成为大算力场景标配。其中GPU并行计算优势明显，CPU+GPU成为目前最流行的异构计算系统，而NPU在特定场景下的性能、效率优势明显，推理端应用潜力巨大，随着大模型多模态发展，硬件需求有望从GPU扩展至周边编解码硬件。

AI加速芯片市场上，英伟达凭借其硬件产品性能的先进性和生态构建的完善性处于市场领导地位，在训练、推理端均占据领先地位。根据Liftr Insights数据，2022年数据中心AI加速市场中，英伟达份额达82%。因此AI芯片需求爆发，英伟达最为受益，其 Q2收入指引110亿美金，预计其数据中心芯片业务收入接近翻倍。国内厂商虽然在硬件产品性能和产业链生态架构方面与前者有所差距，但正在逐步完善产品布局和生态构建，不断缩小与行业龙头厂商的差距，并且英伟达、AMD对华供应高端GPU芯片受限，国产算力芯片迎来国产替代窗口期。

**交换机**：与传统数据中心的网络架构相比，AI数据网络架构会带来更多的交换机端口的需求。交换机具备技术壁垒，中国市场格局稳定。

**光模块**：AI算力带动数据中心内部数据流量较大，光模块速率及数量均有显著提升。训练侧光模块需求与GPU出货量强相关，推理侧光模块需求与数据流量强相关，伴随应用加速渗透，未来推理所需的算力和流量实际上可能远大于训练。目前，训练侧英伟达的A100 GPU主要对应200G光模块和400G光模块，H100 GPU可以对应400G或800G光模块。

根据我们的测算，训练端A100和200G光模块的比例是1：7，H100和800G光模块的比例是1：3.5。800G光模块2022年底开始小批量出货，2023年需求主要来自于英伟达和谷歌。在2023年这个时间点，市场下一代高速率光模块均指向800G光模块，叠加AIGC带来的算力和模型竞赛，我们预计北美各大云厂商和相关科技巨头均有望在2024年大量采购800G光模块，同时2023年也可能提前采购。

**光模块上游——光芯片**：以AWG、PLC等为代表的无源光芯片，国内厂商市占率全球领先。以EEL、VCSEL、DFB等激光器芯片、探测器芯片和调制器芯片为代表的有源光芯片是现代光学技术的重要基石，是有源光器件的重要组成部分。

**液冷**：AI大模型训练和推理所用的GPU服务器功率密度将大幅提升，以英伟达DGX A100服务器为例，其单机最大功率约可达到6.5kW，大幅超过单台普通CPU服务器500w左右的功率水平。

根据《冷板式液冷服务器可靠性白皮书》数据显示，自然风冷的数据中心单柜密度一般只支持8kW-10kW，通常液冷数据中心单机柜可支持30kW以上的散热能力，并能较好演进到100kW以上，相较而言液冷的散热能力和经济性均有明显优势。同时“东数西算” 明确PUE（数据中心总能耗/IT设备能耗）要求，枢纽节点PUE要求更高，同时考虑到整体规划布局，未来新增机柜更多将在枢纽节点内，风冷方案在某些地区可能无法严格满足要求，液冷方案渗透率有望加速提升。目前在AI算力需求的推动下，如浪潮信息、中兴通讯等服务器厂商已经开始大力布局液冷服务器产品。在液冷方案加速渗透过程中，数据中心温控厂商、液冷板制造厂商等有望受益。

**AI服务器**：预计今年Q2-Q3开始逐步释放业绩。具体来看，训练型AI服务器成本中，约7成以上由GPU构成，其余CPU、存储、内存等占比相对较小，均价常达到百万元以上。对于推理型服务器，其GPU成本约为2-3成，整体成本构成与高性能型相近，价格常在20-30万。根据IDC数据，2022年全球AI服务器市场规模202亿美元，同比增长29.8%，占服务器市场规模的比例为16.4%，同比提升1.2pct。

我们认为全球AI服务器市场规模未来3年内将保持高速增长，市场规模分别为395/890/1601亿美元，对应增速96%/125%/80%。根据IDC数据，2022年中国AI服务器市场规模67亿美元，同比增长24%。我们预计，2023-2025年，结合对于全球AI服务器市场规模的预判，以及对于我国份额占比持续提升的假设，我国AI服务器市场规模有望达到134/307/561亿美元，同比增长101%/128%/83%。竞争格局方面，考虑到AI服务器研发和投入上需要更充足的资金及技术支持，国内市场的竞争格局预计将继续向头部集中，保持一超多强的竞争格局。

**IDC**：在数字中国和人工智能推动云计算市场回暖的背景下，IDC作为云基础设施产业链的关键环节，也有望进入需求释放阶段。在过去两年半，受多重因素影响下，云计算需求景气度下行，但IDC建设与供给未出现明显放缓，2021年和2022年分别新增机柜数量120万架和150万架，因此短期内出现供需失衡情况（核心区域供需状况相对良好），部分地区上电率情况一般。所以IDC公司2022年业绩普遍承压。

当前，我们认为国内IDC行业有望边际向好。随着宏观经济向好，平台经济发展恢复，AI等拉动，IDC需求有望逐步释放，叠加2023新增供给量有望较2022年减少（例如三大运营商2022年新增IDC机柜15.6万架，2023年计划新增11.4万架）。展望未来，电信运营商在云计算业务方面仍将实现快速增长，百度、字节跳动等互联网公司在AIGC领域有望实现突破性进展，都将对包括IDC在内的云基础设施产生较大新增需求，相关IDC厂商有望获益。

<https://finance.sina.cn/stock/ggyj/2023-10-21/detail-imzrvyzn4754692.d.html?vt=4>

## 4.2 广发证券

### 4.2.1 先进工艺、先进设备

CFET工艺复杂度进一步提升，光刻-刻蚀-沉积工艺大量增加。CFET设计为扩展摩
尔定律提供了一种有广阔前景的解决方案，并且能够满足日益增长的在有限尺寸内
提高性能和降低功耗的需求。根据台积电在IEDM 2023发表的论文，与传统CMOS
架构相比，在相同的栅极间距下，CFET密度大约高出1.5至2倍。为了实现N/P晶体
管的垂直堆叠并保证良好的电学特性，台积电在纳米片沟道CFET结构中引入了中间
介电隔离（MDI）、内部间隔（INSP）和N/P源漏极隔离（SD-ISO）等结构。这些
结构大大提升了CFET结构的工艺复杂度，需要更多的光刻、刻蚀、沉积等关键设备。

先进封装前道化，带动TSV、键合、减薄等关键设备需求。目前先进封装中硅中介
层和HBM的制造涉及多种前道晶圆制造技术，如光刻、TSV刻蚀、薄膜沉积、晶圆
减薄、化学机械抛光等。这些工艺在传统封装中很少用到，先进封装市场的增长有
望带动相关设备市场持续成长。此外，键合工艺直接决定了垂直互连的密度，是先
进封装中的核心工艺。混合键合技术可以实现铜对铜直接互连，能够将互连间距微
缩至10微米以下，有望成为未来芯片垂直堆叠的主要键合技术。

新技术革新带来新机遇，半导体制造国产替代持续推进。当前，晶体管尺寸微缩已
经趋于物理极限，难以满足爆发性增长的AI/HPC计算需求。晶圆制造技术和先进封
装技术亟需架构革新，引入**晶体管垂直堆叠、3D先进封装等新技术**，工艺复杂度显
著提升，有望推动关键设备市场持续增长。在新技术变革的过程中，国产半导体先
进制造、先进封装产业链相关公司有望加速追赶海外先进公司，提升国产替代份额。
建议关注前道半导体设备北方华创、中微公司、拓荆科技、华海清科、盛美上海、
芯源微等；先进封装通富微电、长电科技、甬矽电子等；半导体材料鼎龙股份、雅
克科技、安集科技、艾森股份等

### 4.2.2 Retimer和CXL

⚫ Astera Labs：高速成长的数据中心连接方案独角兽。Astera Labs 于 2017 年成立至今快速成长，三条产品线专注于解决数据中心 AI 相关的连接和内存瓶颈等问题。
（1）Retimer 芯片：Aries 是公司 PCIe Retimer 芯片业务，Retimer 以数字方式恢复降级的高速信号并重新传输数据，从而实现更高数据带宽；
（2）AEC：Taurus 是公司有源电缆（AEC）模块业务，主要通过以太网扩展服务器和交换机之间的传输；
（3）CXL 内存连接控制器：Leo 系列产品是公司基于 CXL 技术拓展的内存连接控制器业务，主要在于解决“内存墙”问题。公司从成立至今，已获得了超 300 个 design win，目前导入包括了亚马逊、英特尔、AMD、Supermicro 等客户。
⚫ PCIe Retimer：需求和 AI 服务器出货高度相关。解决信号衰减问题主要分三种方案，而 Retimer 有望成为解决信号衰减最具性价比的方案。AIGC 大潮催生各种大模型训练需求，相应拉动了 AI 服务器需求。根据 AsteraLabs 方案，一台 8 卡 GPU 的 AI 服务器至少需要 8 颗 Retimer 芯片，即 Retimer 芯片需求量和 AI 服务器需求高度相关。通用服务器方面，Retimer 芯片可用在 NVMe SSD、NIC、Riser 卡等多达 8 个应用场景使用，但随着 PCIe 5.0 的渗透提升，通用服务器对 PCIe Retimer 需求也相应增加。我们测算 2027 年 PCIe Retimer
芯片市场空间约 9.66 亿元，2023-2027 年 CAGR 达 59.7%。
⚫ AEC：800G 速率或加速 AEC 需求。随着数据中心服务器接口的速率向 56Gbps 的 PAM-4 信号过渡，400G和 800G 速率网络成为主流，DAC 的传输距离大大缩短至 3 米以内。由于 AEC 在电缆内部增加了有源芯片Retimer 或 Redriver，可以补偿一部分铜线传输造成的损耗，以增强和延长信号传输，更符合 AI 集群需求。根
据650 Group预估，AEC市场空间预计从2023年约7000万美元增长到2027年约13亿美元，CAGR达108%。Taurus 系列是 Astera Labs 的 AEC 模块业务，集成了公司的 COSMOS 软件套件。
⚫ CXL：解决 Memory Wall 的方案之一。AI 大模型时代，算力和带宽能力之间的差距越来越大。“内存墙”问题越来越明显，从而限制了整个存算系统的性能。Leo 产品系列是 Astera Lab 的 CXL 内存控制器，通过支持内存扩展和池化来消除带宽/容量瓶颈、降低 TCO 并优化内存利用率，从而加速人工智能和云基础设施。此外，本土厂商澜起科技于 2022 年 5 月发布全球首款 CXL 内存扩展控制器芯片（MXC），三星和海力士相继推出了采用 CXL 内存控制器的 CXL 内存模组。产业链陆续布局推进中。
⚫ 投资建议：建议关注同时布局**Retimer和CXL内存控制器芯片厂商**澜起科技。

### 4.2.3 AI服务器PCB

⚫ AI 服务器中 PCB 性能提升，单机价值量增长。
（1）**AI 服务器相比传统服务器一般增配 GPU 模组，从 PCB面积增加、层数增加和配套 CCL 材料标准提高三个方面，带来 PCB 板性能及单机价值量提升**。以英伟达 DGX系列为例，其采用 GPU 托盘和主板托盘双层结构，主要包括三种 PCB 产品，其中 UBB 用于搭载整个 GPU平台，OAM 用于承载 GPU 芯片，主板用于搭载 CPU、内存、网卡等零部件，规格和价值量随平台同步升级。
（2）相比 DGX 系列服务器，GB200 NVL72 中单 GPU PCB 价值量有望提升。GB200 NVL72 服务器是基于MGX 参考设计和 NVLink Switch 系统的机架，包括 18 个 compute tray 和 9 个 Nvlink switch tray，每个compute tray 里面包含 2 个性能强劲 GB200 超级芯片，主板和 NVLink switch 模组板全面升级，集成度更高、线路更复杂，制程要求和制造成本更高。根据我们测算，相比 DGX 系列，GB200 NVL72 中 GPU 的 PCB 总价值量增加 33%~124%。
⚫ AI PCB 市场规模持续增长，HDI 价值量占比提升。AI 服务器需求驱动服务器 PCB 加速成长，增速高于整体市场。根据 Prismark 数据，服务器与数据存储领域 PCB 市场规模预计在 2023 年达到 82 亿美元，到 2028 年将达到 138 亿美元，CAGR 为 11%，高于同期 PCB 市场整体增速 5.4%。**根据我们测算，AI 服务器 PCB 的市场规模预计将从 2023 年的 3.8 亿美元增长至 2025 年的 40.6 亿美元**，占整体 PCB 比例将从 2023 年的0.5%上升到 2025 年的 4.7%。HDI 在 AI 服务器 PCB 中占比提升，主要由于其优越性能。根据我们测算，相比 DGX 系列，GB200 NVL72 中单 GPU 的 HDI 价值量增加 244%~476%。HDI 技术能够进一步缩小 PCB 上的布线空间和元件间距，提高服务器的集成度和性能。
⚫ 国产厂商竞争优势明显，积极布局 AI 服务器 PCB。PCB 产值国内占比过半，多层板占据主导地位。HDI 被海外厂商主导，国内厂商成长迅速。近几年资本投入较大的 HDI 海外供应商，逐渐将资产开支投向公司其他业务，国内 HDI 起步较晚，但规模及技术能力等方面发展速度较快。国内厂商积极布局 AI 服务器相关 PCB 产
品，沪电股份与胜宏科技为领军企业。根据公司财报，沪电股份为 AI 服务器 PCB 行业龙头，业绩高增长，部分产品已批量交付。胜宏科技为 HDI 板领军企业，根据公司 2022 年年报，公司已实现 4 阶 HDI 及高多层的产品化，6 阶 HDI 产品已在加速布局中，未来成长弹性大。
⚫ 投资建议。AI 服务器 PCB 面积、层数、材料性能持续提升，推动 PCB 单机价值量增长。相比 DGX 系列服务器，GB200 NVL72 中单 GPU PCB 价值量有望提升。AI PCB 市场规模持续增长，HDI 价值量占比提升。国内厂商积极布局 AI 服务器 PCB，产业链迎来新机遇。从“AI 的 iPhone 时刻”到“AI 的引裂变时刻”，建议关注产业链核心受益标的：沪电股份、胜宏科技、工业富联等。

### 4.2.4 以太网交换机

 GPU 集群规模增长趋势显著。在大模型 Scaling Laws 持续有效的背景下，以集群形式的分布式并行训练能够有效节省训练时间与提升 GPU 使用效率，面对不断膨胀的模型参数和训练数据，为尽可能缩短模型训练时间，提升模型迭代效率，集群规模有望实现指数级增长。以英伟达为例，根据其在 COMPUTEX 2024 上发布的升
级规划：
（1）2024 年互联超一万颗 GPU；
（2）2025 年互联超十万颗 GPU；
（3）2026 年互联超百万颗 GPU。
 集群规模扩张推动网络层数增加，进而提升交换机配比。集群内网络搭建需要满足高带宽和低延迟的需求，因此，使用 Fat-Tree（胖树）架构的 CLOS 网络正被广泛应用于计算集群中。随着计算集群规模的持续扩大，交换机网络层数将随之提升。根据英伟达官网，以 SPECTRUM-X 以太网交换机为例，主流型号 SN5600 拥有 64
个 800Gbps 端口。根据论文《A Scalable, Commodity Data Center Network Architecture》中的测算，在不考虑网络收敛和光模块拆分的情况下，不同层数的 CLOS 胖树架构互联 GPU 的上限分别为：
（1）2 层架构：计算网络最多使用 96 个交换机，最多互联 2,048 个 GPU，GPU 与计算网络交换机配比为 64:3；
（2）3 层架构：计算网络最多使用 5,120 个交换机，最多互联 65,536 个 GPU，GPU 与计算网络交换机配比为 64:5；
（3）4 层架构：计算网络最多使用 229,376 个交换机，最多互联 2,097,152 个 GPU，GPU 与交计算网络机的配比为 64:7。
 GPU 集群规模扩张触发 InfiniBand 互联上限，RoCE 协议有望在大集群中更多被应用。InfiniBand 协议中优先考虑尽可能降低网络延迟，而 RoCE 协议则优先考虑网络的兼容性与分布式。在数据交互中，IB 协议中每个GPU 都有自己的 LID（Local ID），两两 GPU 之间交互路径由路由表提前算好，以此实现低延时效果。但根据IB 协议中的报文结构，LID 由一个 16 位的二进制编码组成，因此在 IB 网络协议下，互联的 GPU 上限为2^16=65,536 个。随着集群规模向十万卡级别升级，RoCE 协议组网方案有望在大集群中更多被应用。
 互联速率提升趋势加速，数据中心以太网交换机迎来量价齐升机遇。在千亿级参数的大模型训练中，单次计算迭代内梯度同步需要的通信量就达到了百 GB 量级，随模型参数以及单 GPU 算力持续提升，为充分发挥 GPU计算资源的利用率，对于集群中计算单元的通信速率需要持续升级。Marvell 在 24 年 AI Day 上表示，互联速率
在 AI 的催化下，从之前的每四年翻一倍加速至每两年翻一倍；根据博通官网，其 Tomahawk 5 交换芯片容量已达 51.2Tb/s，可支持 64 个 800Gbps 端口的数据交换，而下一代 Tomahawk 6 芯片交换容量将提升至 102.4Tb/s。
在集群互联规模&互联带宽持续提升的背景下，根据 Arista 官网预测，**26 年数据中心以太网交换机市场规模有望从 23 年的 200 亿美元出头提升至接近 300 亿美元**，市场规模提升显著，产业链公司有望深度受益。
 建议关注。
（1）交换机 PCB 龙头：沪电股份。根据沪电股份年报，公司基于 112Gbps 速率 51.2T 的盒式 800G交换机已批量交付，224Gbps 产品开始预研。
（2）本土交换机 ODM：华勤技术。根据公司 24 年一月投资者关系活动记录表 23 年三季度，公司实现头部互联网客户 TH5 主流交换机中标，成功突破交换机大客户。

## 4.2.5 总结：算、连、存是AI算力硬件的核心

大模型的技术栈从下而上分为**计算层、框架层、模型层、接口层、应用层**。算力基础设施硬件位于底层计算层，是大模型技术的基础，直接决定了模型的规模、训练效率和推理效率。

AI算力硬件主要包括算、连、存三个部分。**计算部分主要包括GPU、CPU、ASIC等算力芯片**，是AI硬件的核心，通过执行各种算法和数据处理任务，直接影响AI模型的训练速度和推理效率；**存储部分包括显存、内存、高速缓存和硬盘等**，用于存储和快速访问大量数据和模型参数，并在计算过程中提供快速的数据读写支持，决定了模型的规模和训练及推理的效率；**互连部分包括各种总线、网络和通信协议**，用于连接和传输数据，确保各个硬件组件之间的高效通信，提高整体系统的性能和响应速度。

![image](/picture/big_model.png)

![image](/picture/AI_hardware_chaine.png)